{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/CoreTheGreat/HBPU-Machine-Learning-Course/blob/main/ML_Chapter3_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lPboLx_o0UxI"
   },
   "source": [
    "# 第三章：分类\n",
    "湖北理工学院《机器学习》课程资料\n",
    "\n",
    "作者：李辉楚吴\n",
    "\n",
    "笔记内容概述:\n",
    "* 3.1 逻辑回归与二分类问题\n",
    "* 3.2 常用的二分类模型——支持向量机\n",
    "* 3.3 常用的二分类模型——决策树\n",
    "* 3.4 二分类模型的度量\n",
    "* 3.5 由二分类到多分类\n",
    "* 3.6 实验3：基于机器学习方法的手写字母识别\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ifpm7Sql4U09"
   },
   "source": [
    "## 3.1 逻辑回归与二分类问题\n",
    "\n",
    "3.1.1 利用torchvision载入训练数据MINST\n",
    "\n",
    "MINST是一个小型的基于灰度图像(图像大小1x28x28)的手写字母识别数据集，包含60000个训练数据，10000个测试数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "sM-ziKb94S9_",
    "outputId": "9a8bd59b-1ed4-47e3-e118-cee1849a610a"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, mean_absolute_error\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "import time\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import font_manager\n",
    "font_manager.fontManager.addfont('./Data/simhei.ttf') # Add the font\n",
    "matplotlib.rc('font', family='SimHei') # Set the font\n",
    "\n",
    "color_list = ['tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:purple', 'tab:brown', 'tab:pink', 'tab:gray', 'tab:olive', 'tab:cyan']\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "label_size = 18 # Label size\n",
    "ticklabel_size = 14 # Tick label size\n",
    "\n",
    "# Load the MNIST dataset to display\n",
    "imgDisp = torchvision.datasets.MNIST(root='./data', train=False, download=True)\n",
    "img, label = imgDisp[0]\n",
    "\n",
    "print(f'Image size is {img.size}')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7,7))\n",
    "ax.imshow(img, cmap='gray')\n",
    "ax.tick_params(axis='both', which='major', labelsize=ticklabel_size) # Set tick label size\n",
    "ax.set_title(f\"Label: {label}\", fontsize=label_size)\n",
    "# plt.savefig(f'exp_character{label}.png', dpi=300) # Make figure clearer\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BWPSDyOq5qOO",
    "outputId": "9aed06f2-67a9-4a6f-f00c-d91554c3a260"
   },
   "outputs": [],
   "source": [
    "class ftrExtract(object):\n",
    "    def __call__(self, tensor):\n",
    "        tensor = tensor.squeeze()\n",
    "\n",
    "        mean_width = tensor.mean(axis=0)\n",
    "        mean_height = tensor.mean(axis=1)\n",
    "\n",
    "        std_width = tensor.std(axis=0)\n",
    "        std_height = tensor.std(axis=1)\n",
    "\n",
    "        ftrs = torch.cat([mean_width, mean_height, std_width, std_height])\n",
    "\n",
    "        return ftrs\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(), ftrExtract()])\n",
    "\n",
    "# Load the MNIST dataset\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Count number of each class in trainset\n",
    "train_class_counts = {}\n",
    "for _, label in trainset:\n",
    "    if label not in train_class_counts:\n",
    "        train_class_counts[label] = 0\n",
    "    train_class_counts[label] += 1\n",
    "\n",
    "# Count number of each class in testset\n",
    "test_class_counts = {}\n",
    "for _, label in testset:\n",
    "    if label not in test_class_counts:\n",
    "        test_class_counts[label] = 0\n",
    "    test_class_counts[label] += 1\n",
    "\n",
    "# Print results\n",
    "for i in range(10):\n",
    "    cls_counts_train = train_class_counts.get(i, 0)\n",
    "    cls_ratio_train = cls_counts_train / len(trainset)\n",
    "    cls_counts_test = test_class_counts.get(i, 0)\n",
    "    cls_ratio_test = cls_counts_test / len(testset)\n",
    "\n",
    "    print(f\"Class {i}: Trainset - {cls_counts_train} ({cls_ratio_train:.2%}), Testset - {cls_counts_test} ({cls_ratio_test:.2%})\")\n",
    "\n",
    "batch_size = 42\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "# Get a batch of training data\n",
    "dataiter = iter(trainloader)\n",
    "data, labels = next(dataiter)\n",
    "\n",
    "input_size = data[0].numpy().shape[0]\n",
    "print(f'Input_size is {input_size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BtGNbqlSKnC-"
   },
   "source": [
    "3.1.2 使用线性回归识别手写字母"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to numpy arrays\n",
    "X_train = []\n",
    "y_train = []\n",
    "for batch_image, batch_label in trainloader:\n",
    "    X_train.append(batch_image.view(-1, input_size).numpy())\n",
    "    y_train.append(batch_label.numpy())\n",
    "\n",
    "X_train = np.vstack(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "print(f'Shapes of X_train and Y_train: {X_train.shape} and {y_train.shape}')\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "for batch_image, batch_label in testloader:\n",
    "    X_test.append(batch_image.view(-1, input_size).numpy())\n",
    "    y_test.append(batch_label.numpy())\n",
    "\n",
    "X_test = np.vstack(X_test)\n",
    "y_test = np.concatenate(y_test)\n",
    "\n",
    "print(f'Shapes of X_test and y_test: {X_test.shape} and {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用回归的方法做分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the linear regression model\n",
    "lr_model = LinearRegression()\n",
    "\n",
    "# Train the model\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = lr_model.predict(X_test)\n",
    "\n",
    "# Round predictions to nearest integer for classification\n",
    "y_pred_rounded = np.round(y_pred).astype(int)\n",
    "print(f\"Predicted classes: {np.unique(y_pred_rounded)}\")\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = np.mean(y_pred_rounded == y_test)\n",
    "print(f\"Real classes: {np.unique(y_test)}\")\n",
    "print(f\"Accuracy of linear regression model: {accuracy:.4f}\")\n",
    "\n",
    "# Calculate and print classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_rounded))\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "cm = confusion_matrix(y_test, y_pred_rounded)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "\n",
    "plt.savefig(f'Regression_for_classification.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用逻辑回归做分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the linear regression model\n",
    "lr_model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Train the model\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = lr_model.predict(X_test)\n",
    "y_pred_proba = lr_model.predict_proba(X_test)\n",
    "\n",
    "# Round predictions to nearest integer for classification\n",
    "y_pred_rounded = np.round(y_pred).astype(int)\n",
    "print(f\"Predicted classes: {np.unique(y_pred_rounded)}\")\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy of logistic regression model: {accuracy:.4f}\")\n",
    "\n",
    "# Calculate and print classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "\n",
    "plt.savefig(f'Logicregression_for_classification.png', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j2CdFQFnL_jA"
   },
   "source": [
    "3.1.3 使用逻辑回归识别手写字母\"1\"\n",
    "\n",
    "构建二分类数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qdaSQw3bAouJ"
   },
   "outputs": [],
   "source": [
    "# Extract features and labels from trainset\n",
    "x_train = []\n",
    "y_train = []\n",
    "for image, label in trainset:\n",
    "    x_train.append(image.numpy())\n",
    "    y_train.append(1 if label == 1 else 0)  # Set label to 1 for character 1, 0 otherwise\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "# Extract features and labels from trainset\n",
    "x_test = []\n",
    "y_test = []\n",
    "for image, label in testset:\n",
    "    x_test.append(image.numpy())\n",
    "    y_test.append(1 if label == 1 else 0)  # Set label to 1 for character 1, 0 otherwise\n",
    "\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D92HNTRc6MCC"
   },
   "source": [
    "训练逻辑回归模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c6PY2ospzv60",
    "outputId": "b3767883-0d3c-4cbe-e186-fdd50ad9042b"
   },
   "outputs": [],
   "source": [
    "# Define logic regression model\n",
    "mdl_logic = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Train model\n",
    "start_time = time.time()\n",
    "mdl_logic.fit(x_train, y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f'Training time: {end_time - start_time:.2f} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oVddyjIo6P0H"
   },
   "source": [
    "模型测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q7wjYqpI6AJM",
    "outputId": "a2e4156c-d1a6-4358-f0ad-0835d6c267a4"
   },
   "outputs": [],
   "source": [
    "y_pred_logic = mdl_logic.predict(x_test)\n",
    "y_proba_logic = mdl_logic.predict_proba(x_test) # Output ratio\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_logic)\n",
    "precision = precision_score(y_test, y_pred_logic)\n",
    "recall = recall_score(y_test, y_pred_logic)\n",
    "f1 = f1_score(y_test, y_pred_logic)\n",
    "\n",
    "print(f'Precision: {precision:.4f}, Recall: {recall:.4f}, Accuracy: {accuracy:.4f}, F1-Score: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gg4PU499y9qj"
   },
   "source": [
    "案例演示：随机选取图片，输出判断结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "JWaTWosQyt-o",
    "outputId": "1dac9a8c-4a1d-46d6-a5e3-35ec7fb4d605"
   },
   "outputs": [],
   "source": [
    "# Random select 3 examples from imgDisp and testset\n",
    "np.random.seed(42)\n",
    "idx = np.random.choice(len(imgDisp), 3)\n",
    "\n",
    "# Select instances\n",
    "imgDisp_select = [imgDisp[i] for i in idx]\n",
    "x_select = x_test[idx]\n",
    "y_select = y_test[idx]\n",
    "\n",
    "y_select_proba = mdl_logic.predict_proba(x_select)\n",
    "\n",
    "# Check the selected instances' labels are the same\n",
    "for i in range(len(idx)):\n",
    "    print(f'Sample {i+1}: imgDisp label is {imgDisp_select[i][1]}, x label is {y_select[i]}')\n",
    "\n",
    "    # Display image from imgDisp\n",
    "    fig, ax = plt.subplots(figsize=(7,7))\n",
    "    ax.imshow(imgDisp_select[i][0], cmap='gray')\n",
    "    ax.tick_params(axis='both', which='major', labelsize=ticklabel_size) # Set tick label size\n",
    "    ax.set_title(f\"Label: {imgDisp_select[i][1]}, Prediction: {y_select_proba[i,1]:.4f}\", fontsize=label_size)\n",
    "\n",
    "    # plt.savefig(f'binary_prediction_{i+1}.png', dpi=300) # Make figure clearer\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vK7Nd0ATTjpC"
   },
   "source": [
    "## 3.2 常用的二分类模型——支持向量机"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pyu18U8POAqC",
    "outputId": "4675f0dc-2e39-4941-fa3f-4d39e2c4b912"
   },
   "outputs": [],
   "source": [
    "# Define SVM classifier\n",
    "mdl_svm = svm.SVC(kernel='linear', probability=True)\n",
    "\n",
    "# Train model\n",
    "start_time = time.time()\n",
    "mdl_svm.fit(x_train, y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f'Training time: {end_time - start_time:.2f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NhRcX38R7GpP",
    "outputId": "db20fdca-acd4-4111-fb45-334f0c491b54"
   },
   "outputs": [],
   "source": [
    "# Make predictions and evaluate the model\n",
    "y_pred_svm = mdl_svm.predict(x_test)\n",
    "y_proba_svm = mdl_svm.predict_proba(x_test) # Output ratio\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_svm)\n",
    "precision = precision_score(y_test, y_pred_svm)\n",
    "recall = recall_score(y_test, y_pred_svm)\n",
    "f1 = f1_score(y_test, y_pred_svm)\n",
    "\n",
    "print(f'Precision: {precision:.4f}, Recall: {recall:.4f}, Accuracy: {accuracy:.4f}, F1-Score: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m2njQ-yxpqju"
   },
   "source": [
    "## 3.3 常用的二分类模型——决策树和随机森林"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vEwfIl7uazAA",
    "outputId": "4abe6249-5379-41a1-8ee8-be53eb0e2cea"
   },
   "outputs": [],
   "source": [
    "# Define DecisionTree classifier\n",
    "mdl_dt = tree.DecisionTreeClassifier()\n",
    "\n",
    "# Train model\n",
    "start_time = time.time()\n",
    "mdl_dt.fit(x_train, y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f'Training time: {end_time - start_time:.2f} seconds')\n",
    "\n",
    "# Define Random Forest classifier\n",
    "mdl_rf = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "# Train model\n",
    "start_time = time.time()\n",
    "mdl_rf.fit(x_train, y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f'Training time: {end_time - start_time:.2f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DiBlPKs9fNaM",
    "outputId": "70bf3572-3b2c-4888-f5cb-bee4d3aa2127"
   },
   "outputs": [],
   "source": [
    "y_pred_dt = mdl_dt.predict(x_test)\n",
    "y_proba_dt = mdl_dt.predict_proba(x_test) # Output ratio\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_dt)\n",
    "precision = precision_score(y_test, y_pred_dt)\n",
    "recall = recall_score(y_test, y_pred_dt)\n",
    "f1 = f1_score(y_test, y_pred_dt)\n",
    "\n",
    "print(f'Precision: {precision:.4f}, Recall: {recall:.4f}, Accuracy: {accuracy:.4f}, F1-Score: {f1:.4f}')\n",
    "\n",
    "y_pred_rf = mdl_rf.predict(x_test)\n",
    "y_proba_rf = mdl_rf.predict_proba(x_test) # Output ratio\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_rf)\n",
    "precision = precision_score(y_test, y_pred_rf)\n",
    "recall = recall_score(y_test, y_pred_rf)\n",
    "f1 = f1_score(y_test, y_pred_rf)\n",
    "\n",
    "print(f'Precision: {precision:.4f}, Recall: {recall:.4f}, Accuracy: {accuracy:.4f}, F1-Score: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ok1YZCFqNAuH"
   },
   "source": [
    "## 3.4 二分类模型的度量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A9QJr7SMOCBM"
   },
   "source": [
    "准确率、召回率、敏感性、特异性、精确度、F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R1-5Gyl5SWOp",
    "outputId": "5db21c58-1745-4fee-817f-2e80615e28b9"
   },
   "outputs": [],
   "source": [
    "def cls_counts(y_test, y_proba, th=0.5):\n",
    "    y_pred = (y_proba[:,1] > th).astype(int)\n",
    "\n",
    "    tp_idx = (y_test == 1) & (y_pred == 1)\n",
    "    fp_idx = (y_test == 0) & (y_pred == 1)\n",
    "    tn_idx = (y_test == 0) & (y_pred == 0)\n",
    "    fn_idx = (y_test == 1) & (y_pred == 0)\n",
    "\n",
    "    tp = np.sum(tp_idx)\n",
    "    fp = np.sum(fp_idx)\n",
    "    tn = np.sum(tn_idx)\n",
    "    fn = np.sum(fn_idx)\n",
    "\n",
    "    return th, (tp, fp, tn, fn)\n",
    "\n",
    "th, (tp, fp, tn, fn) = cls_counts(y_test, y_proba_logic)\n",
    "print(f'Threshold {th}, TP: {tp}, FP: {fp}, TN: {tn}, FN: {fn}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 522
    },
    "id": "90MR_dKrArN_",
    "outputId": "202f045a-f9ff-4e2c-c4a3-41bc015ca26b"
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(th, tp, fp, tn, fn):\n",
    "    \"\"\"Plots a confusion matrix given the number of true positives, false positives,\n",
    "    true negatives, and false negatives.\"\"\"\n",
    "    global label_size, ticklabel_size # Set global variables of font size\n",
    "\n",
    "    cm = np.array([[tn, fp], [fn, tp]])\n",
    "\n",
    "    # Display the confusion matrix as a heatmap\n",
    "    fig, ax = plt.subplots(figsize=(5,5))\n",
    "    img = ax.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "\n",
    "    # Add labels to the axes\n",
    "    tick_marks = np.arange(2)\n",
    "    ax.set_xticks(tick_marks, ['阴(N)', '阳(P)'], fontsize=ticklabel_size)\n",
    "    ax.set_yticks(tick_marks, ['真(T)', '假(F)'], fontsize=ticklabel_size)\n",
    "\n",
    "    # Add the count of each category to the plot\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            plt.text(j, i, format(cm[i, j], 'd'),\n",
    "                     fontsize=ticklabel_size,\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    ax.tick_params(axis='both', which='major', labelsize=ticklabel_size) # Set tick label size\n",
    "\n",
    "    ax.set_ylabel('客观事实（Real Label）', fontsize=label_size)\n",
    "    ax.set_xlabel('主观判断（Predicted Label）', fontsize=label_size)\n",
    "    ax.set_title(f'判断阈值(Threshold): {th}', fontsize=label_size)\n",
    "\n",
    "    return fig, ax\n",
    "\n",
    "def get_scores(tp, fp, tn, fn):\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn) # Also called sensitivity\n",
    "    accuracy = (tp + tn) / (tp + fp + tn + fn)\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "    specificity = tn / (tn + fp)\n",
    "\n",
    "    return precision, recall, specificity, accuracy, f1\n",
    "\n",
    "precision, recall, specificity, accuracy, f1 = get_scores(tp, fp, tn, fn)\n",
    "print(f'Precision: {precision:.4f}, Recall (Sensitivity): {recall:.4f}, Specificity: {specificity:.4f}, Accuracy: {accuracy:.4f}, F1-Score: {f1:.4f}')\n",
    "\n",
    "# Example usage (replace with your actual values)\n",
    "fig, ax = plot_confusion_matrix(th, tp, fp, tn, fn)\n",
    "\n",
    "# plt.savefig(f'binary_confusion_matrix.png', dpi=300) # Make figure clearer\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 522
    },
    "id": "w-rkKSZfRhdL",
    "outputId": "6a5d29d3-4469-43bd-da89-7d7e670bf61d"
   },
   "outputs": [],
   "source": [
    "th = 0.1\n",
    "th, (tp, fp, tn, fn) = cls_counts(y_test, y_proba_logic, th)\n",
    "\n",
    "precision, recall, specificity, accuracy, f1 = get_scores(tp, fp, tn, fn)\n",
    "print(f'Precision: {precision:.4f}, Recall (Sensitivity): {recall:.4f}, Specificity: {specificity:.4f}, Accuracy: {accuracy:.4f}, F1-Score: {f1:.4f}')\n",
    "\n",
    "fig, ax = plot_confusion_matrix(th, tp, fp, tn, fn)\n",
    "# plt.savefig(f'binary_confusion_matrix_0D1.png', dpi=300) # Make figure clearer\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 522
    },
    "id": "GN6gBEqlSR7v",
    "outputId": "1526103a-97e4-4a41-f333-e2c06b8600fc"
   },
   "outputs": [],
   "source": [
    "th = 0.9\n",
    "th, (tp, fp, tn, fn) = cls_counts(y_test, y_proba_logic, th)\n",
    "\n",
    "precision, recall, specificity, accuracy, f1 = get_scores(tp, fp, tn, fn)\n",
    "print(f'Precision: {precision:.4f}, Recall (Sensitivity): {recall:.4f}, Specificity: {specificity:.4f}, Accuracy: {accuracy:.4f}, F1-Score: {f1:.4f}')\n",
    "\n",
    "fig, ax = plot_confusion_matrix(th, tp, fp, tn, fn)\n",
    "# plt.savefig(f'binary_confusion_matrix_0D9.png', dpi=300) # Make figure clearer\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XNGhtZrLWSAY"
   },
   "source": [
    "ROC（Receiver operating characteristic curve）接收者操作特征曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 559
    },
    "id": "qCfPvjQBYJJN",
    "outputId": "5bb82ba4-6844-4a32-82e4-6ef1398d2a57"
   },
   "outputs": [],
   "source": [
    "def plot_roc_curve_base():\n",
    "    \"\"\"Plots the ROC curve and computes AUC.\"\"\"\n",
    "    global label_size, ticklabel_size # Set global variables of font size\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8,6))\n",
    "\n",
    "    ax.plot([0, 1], [0, 1], color='grey', lw=2, linestyle='--')\n",
    "    ax.set_xlim([0.0, 1.0])\n",
    "    ax.set_ylim([0.0, 1.0])\n",
    "    ax.tick_params(axis='both', which='major', labelsize=ticklabel_size) # Set tick label size\n",
    "\n",
    "    ax.set_xlabel('False Positive Rate (FPR)', fontsize=label_size)\n",
    "    ax.set_ylabel('True Positive Rate (TPR)', fontsize=label_size)\n",
    "\n",
    "    return fig, ax\n",
    "\n",
    "def add_roc_curve(ax, y_true, y_proba, curve_color, curve_label):\n",
    "    \"\"\"Plots the ROC curve and computes AUC.\"\"\"\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_proba)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    roc = ax.plot(fpr, tpr, color=curve_color, lw=2, label=f'{curve_label} (AUC = {roc_auc:.4f})')\n",
    "\n",
    "    return roc_auc, fpr, tpr, thresholds\n",
    "\n",
    "fig, ax = plot_roc_curve_base()\n",
    "\n",
    "roc_auc_logic, fpr_logic, tpr_logic, thresholds_logic = add_roc_curve(ax, y_test, y_proba_logic[:,1], color_list[0], '逻辑回归')\n",
    "roc_auc_logic, fpr_logic, tpr_logic, thresholds_logic = add_roc_curve(ax, y_test, y_proba_svm[:,1], color_list[1], '支持向量机')\n",
    "roc_auc_logic, fpr_logic, tpr_logic, thresholds_logic = add_roc_curve(ax, y_test, y_proba_dt[:,1], color_list[2], '决策树')\n",
    "roc_auc_logic, fpr_logic, tpr_logic, thresholds_logic = add_roc_curve(ax, y_test, y_proba_rf[:,1], color_list[3], '随机森林')\n",
    "\n",
    "plt.legend(loc=\"lower right\", fontsize=ticklabel_size)\n",
    "# plt.savefig(f'binary_roc_curve.png', dpi=300) # Make figure clearer\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gapReol-qyYW"
   },
   "source": [
    "## 3.5 由二分类到多分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IcqIRYK3m_8e"
   },
   "outputs": [],
   "source": [
    "# Extract features and labels from trainset\n",
    "x_train = []\n",
    "y_train = []\n",
    "for image, label in trainset:\n",
    "    x_train.append(image.numpy())\n",
    "    y_train.append(label)\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "# Extract features and labels from trainset\n",
    "x_test = []\n",
    "y_test = []\n",
    "for image, label in testset:\n",
    "    x_test.append(image.numpy())\n",
    "    y_test.append(label)\n",
    "\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Sjl2lRIOT3W"
   },
   "source": [
    "3.5.1 一对多（One-vs-Rest）方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZCLadsuz1cyN",
    "outputId": "9d7fca6c-d1bc-4ce6-9c7d-954f16ca54b9"
   },
   "outputs": [],
   "source": [
    "# Define logic multi-classifier\n",
    "mdl_logic_ovr = OneVsRestClassifier(LogisticRegression(max_iter=1000))\n",
    "\n",
    "# Train model\n",
    "start_time = time.time()\n",
    "mdl_logic_ovr.fit(x_train, y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f'Training time: {end_time - start_time:.2f} seconds')\n",
    "\n",
    "# Make predictions and evaluate the model\n",
    "y_pred_logic_ovr = mdl_logic_ovr.predict(x_test)\n",
    "y_proba_logic_ovr = mdl_logic_ovr.predict_proba(x_test) # Output ratio\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_logic_ovr)\n",
    "print(f'Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JKwTr3HTO_ZG",
    "outputId": "d0ec57ad-eee1-411b-c422-225040901c63"
   },
   "outputs": [],
   "source": [
    "# Get class list: 0, 1, ..., 9\n",
    "class_list = np.sort(np.unique(y_train))\n",
    "\n",
    "# Create model list\n",
    "mdl_logic_list = []\n",
    "for c in class_list:\n",
    "    mdl_logic_list.append(LogisticRegression(max_iter=1000))\n",
    "\n",
    "# Train models seperately\n",
    "for i in range(len(class_list)):\n",
    "    start_time = time.time()\n",
    "    mdl_logic_list[i].fit(x_train, (y_train == class_list[i]).astype(int))\n",
    "    end_time = time.time()\n",
    "    print(f'Training class {class_list[i]}, Training time: {end_time - start_time:.2f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 559
    },
    "id": "ypZ5d4NydeM1",
    "outputId": "b84e4420-fa31-4922-d51b-e13e61a571f3"
   },
   "outputs": [],
   "source": [
    "# Plot ROC curve\n",
    "fig, ax = plot_roc_curve_base()\n",
    "\n",
    "# Draw ROC of individual classifier\n",
    "for i in range(len(class_list)):\n",
    "    # Make predictions and evaluate the model\n",
    "    y_test_trans = (y_test == class_list[i]).astype(int)\n",
    "    y_proba = mdl_logic_list[i].predict_proba(x_test) # Output ratio\n",
    "\n",
    "    roc_auc_logic, fpr_logic, tpr_logic, thresholds_logic = add_roc_curve(ax, y_test_trans, y_proba[:,1], color_list[i], f'{class_list[i]}')\n",
    "\n",
    "plt.legend(loc=\"lower right\", fontsize=ticklabel_size)\n",
    "# plt.savefig(f'binary_roc_curve_ovr.png', dpi=300) # Make figure clearer\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "vsSNVXr4-Ir-",
    "outputId": "e209bb61-0e22-4ced-b74a-db1fbec50ac6"
   },
   "outputs": [],
   "source": [
    "sample_num = 10\n",
    "\n",
    "# Random select 3 examples from imgDisp and testset\n",
    "np.random.seed(1)\n",
    "idx = np.random.choice(len(imgDisp), sample_num)\n",
    "\n",
    "# Select instances\n",
    "imgDisp_select = [imgDisp[i] for i in idx]\n",
    "testset_select = [testset[i] for i in idx]\n",
    "\n",
    "# Check the selected instances' labels are the same\n",
    "for i in range(sample_num):\n",
    "    x = testset_select[i][0].view(-1, input_size)\n",
    "\n",
    "    # Using model to predict character\n",
    "    y_pred_list = []\n",
    "    for j in range(len(mdl_logic_list)):\n",
    "        y_pred_list.append(mdl_logic_list[j].predict(x))\n",
    "\n",
    "    y_pred = np.argmax(np.array(y_pred_list), axis=0)[0]\n",
    "\n",
    "    # Display image from imgDisp\n",
    "    fig, ax = plt.subplots(figsize=(7,7))\n",
    "    ax.imshow(imgDisp_select[i][0], cmap='gray')\n",
    "    ax.tick_params(axis='both', which='major', labelsize=ticklabel_size) # Set tick label size\n",
    "    ax.set_title(f\"Label: {imgDisp_select[i][1]}, Prediction Label: {y_pred}\", fontsize=label_size)\n",
    "\n",
    "    print(f'Sample {i+1}: imgDisp label is {imgDisp_select[i][1]}, testset label is {testset_select[i][1]}, predict label is {y_pred}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BZjng2_U0v1d",
    "outputId": "99c4f34a-fadc-49b1-d1ff-93c3be06014c"
   },
   "outputs": [],
   "source": [
    "# Prediction\n",
    "y_pred_list = []\n",
    "for i in range(len(mdl_logic_list)):\n",
    "    y_pred_list.append(mdl_logic_list[i].predict(x_test))\n",
    "\n",
    "y_pred = np.argmax(np.array(y_pred_list), axis=0)\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wxvDfOE9HEsD"
   },
   "source": [
    "混淆矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 782
    },
    "id": "PXC8Yi62HHVb",
    "outputId": "c68a32c7-3a54-492e-fb6f-83ae02ca851c"
   },
   "outputs": [],
   "source": [
    "# Create confusion matrix\n",
    "cm_test = np.zeros((10, 10))\n",
    "for i in range(len(y_test)):\n",
    "    cm_test[y_test[i], y_pred[i]] += 1\n",
    "\n",
    "# Display confusion matrix\n",
    "fig, ax = plt.subplots(figsize=(9,9))\n",
    "im = ax.imshow(cm_test, cmap=plt.cm.Blues, interpolation='nearest')\n",
    "\n",
    "# Loop over data dimensions and create text annotations.\n",
    "for i in range(cm_test.shape[0]):\n",
    "    for j in range(cm_test.shape[1]):\n",
    "        ax.text(j, i, cm_test[i, j], fontsize=ticklabel_size, ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if cm_test[i, j] > cm_test.max() / 2. else \"black\")\n",
    "\n",
    "ax.set_xlabel('Predicted label', fontsize=label_size)\n",
    "ax.set_ylabel('True label', fontsize=label_size)\n",
    "\n",
    "ax.set_xticks(np.arange(10))\n",
    "ax.set_xticklabels(np.arange(10))\n",
    "\n",
    "ax.set_yticks(np.arange(10))\n",
    "ax.set_yticklabels(np.arange(10))\n",
    "\n",
    "ax.tick_params(axis='both', which='major', labelsize=ticklabel_size)\n",
    "\n",
    "# plt.savefig(f'confusion_matrix_numel.png', dpi=300) # Make figure clearer\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 782
    },
    "id": "8y4cmMSMLNW0",
    "outputId": "b6cd9070-ada0-4fac-eb06-c535d8f358d2"
   },
   "outputs": [],
   "source": [
    "# Create confusion matrix\n",
    "cm_test = np.zeros((10, 10))\n",
    "for i in range(len(y_test)):\n",
    "    cm_test[y_test[i], y_pred[i]] += 1\n",
    "\n",
    "# Change value to ratio\n",
    "cm_test = cm_test / np.sum(cm_test, axis=1, keepdims=True)\n",
    "\n",
    "# Display confusion matrix\n",
    "fig, ax = plt.subplots(figsize=(9,9))\n",
    "im = ax.imshow(cm_test, cmap=plt.cm.Blues, interpolation='nearest')\n",
    "\n",
    "# Loop over data dimensions and create text annotations.\n",
    "for i in range(cm_test.shape[0]):\n",
    "    for j in range(cm_test.shape[1]):\n",
    "        ax.text(j, i, format(cm_test[i, j], '.2f'), fontsize=ticklabel_size, ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if cm_test[i, j] > cm_test.max() / 2. else \"black\")\n",
    "\n",
    "ax.set_xlabel('Predicted label', fontsize=label_size)\n",
    "ax.set_ylabel('True label', fontsize=label_size)\n",
    "\n",
    "ax.set_xticks(np.arange(10))\n",
    "ax.set_xticklabels(np.arange(10))\n",
    "\n",
    "ax.set_yticks(np.arange(10))\n",
    "ax.set_yticklabels(np.arange(10))\n",
    "\n",
    "ax.tick_params(axis='both', which='major', labelsize=ticklabel_size)\n",
    "\n",
    "# plt.savefig(f'confusion_matrix_ratio.png', dpi=300) # Make figure clearer\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oRXvzocEbGWj"
   },
   "source": [
    "3.5.2 一对一（One-vs-One）方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XP8-K-A7pwq_",
    "outputId": "912700a3-b4b8-40a1-f3c3-05424001cded"
   },
   "outputs": [],
   "source": [
    "# Define logic regression classifier\n",
    "mdl_logic_ovo = OneVsOneClassifier(LogisticRegression(max_iter=1000))\n",
    "\n",
    "# Train model\n",
    "start_time = time.time()\n",
    "mdl_logic_ovo.fit(x_train, y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f'Training time: {end_time - start_time:.2f} seconds')\n",
    "\n",
    "# Make predictions and evaluate the model\n",
    "y_pred = mdl_logic_ovo.predict(x_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e69VMFy-lkg-",
    "outputId": "bd33372e-0617-4da7-e00d-ea7de45d3ad4"
   },
   "outputs": [],
   "source": [
    "# Get class list: 0, 1, ..., 9\n",
    "class_list = np.sort(np.unique(y_train))\n",
    "\n",
    "# Create model matrix to save models\n",
    "mdl_logic_matrix = {}\n",
    "for cls_p in class_list:\n",
    "    mdl_logic_matrix[cls_p] = {}\n",
    "    for cls_n in class_list:\n",
    "        if cls_p == cls_n:\n",
    "            continue\n",
    "        mdl_logic_matrix[cls_p][cls_n] = LogisticRegression(max_iter=1000)\n",
    "\n",
    "for cls_p in class_list:\n",
    "    # Training data of positive class\n",
    "    x_train_ovo_p = x_train[(y_train == cls_p), :]\n",
    "    y_train_ovo_p = np.ones(x_train_ovo_p.shape[0])\n",
    "\n",
    "    # Testing data of positive class\n",
    "    x_test_ovo_p = x_test[(y_test == cls_p), :]\n",
    "    y_test_ovo_p = np.ones(x_test_ovo_p.shape[0])\n",
    "\n",
    "    for cls_n in class_list:\n",
    "        if cls_p == cls_n:\n",
    "            continue\n",
    "\n",
    "        # Training data of negative class\n",
    "        x_train_ovo_n = x_train[(y_train == cls_n), :]\n",
    "        y_train_ovo_n = np.zeros(x_train_ovo_n.shape[0])\n",
    "\n",
    "        # Testing data of negative class\n",
    "        x_test_ovo_n = x_test[(y_test == cls_n), :]\n",
    "        y_test_ovo_n = np.zeros(x_test_ovo_n.shape[0])\n",
    "\n",
    "        # Concatenate data for training\n",
    "        x_train_ovo = np.concatenate((x_train_ovo_p, x_train_ovo_n), axis=0)\n",
    "        y_train_ovo = np.concatenate((y_train_ovo_p, y_train_ovo_n), axis=0)\n",
    "\n",
    "        # Model training\n",
    "        start_time = time.time()\n",
    "        mdl_logic_matrix[cls_p][cls_n].fit(x_train_ovo, y_train_ovo)\n",
    "        end_time = time.time()\n",
    "\n",
    "        # Concatenate data for testing\n",
    "        x_test_ovo = np.concatenate((x_test_ovo_p, x_test_ovo_n), axis=0)\n",
    "        y_test_ovo = np.concatenate((y_test_ovo_p, y_test_ovo_n), axis=0)\n",
    "\n",
    "        # Test model on sub-task\n",
    "        y_proba_ovo = mdl_logic_matrix[cls_p][cls_n].predict_proba(x_test_ovo) # Output ratio\n",
    "\n",
    "        # Display results\n",
    "        _, (tp, fp, tn, fn) = cls_counts(y_test_ovo, y_proba_ovo)\n",
    "        precision, recall, specificity, accuracy, f1 = get_scores(tp, fp, tn, fn)\n",
    "        print(f'Training class {cls_p} ({x_train_ovo_p.shape[0]}) vs class {cls_n} ({x_train_ovo_n.shape[0]}), Training time: {end_time - start_time:.2f} seconds, Precision: {precision:.4f}, Recall (Sensitivity): {recall:.4f}, Specificity: {specificity:.4f}, Accuracy: {accuracy:.4f}, F1-Score: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sat6M2RLNBxB",
    "outputId": "7948d284-554e-46fe-98f4-e3bf90687bb5"
   },
   "outputs": [],
   "source": [
    "# Select class 1\n",
    "x_test_select = x_test[:, :]\n",
    "\n",
    "# Prediction\n",
    "y_pred_counts = np.zeros((x_test_select.shape[0], len(class_list)))\n",
    "\n",
    "for cls_p in class_list:\n",
    "    for cls_n in class_list:\n",
    "        if cls_p == cls_n:\n",
    "            continue\n",
    "\n",
    "        y_pred_counts[:, cls_p] = y_pred_counts[:, cls_p] + mdl_logic_matrix[cls_p][cls_n].predict(x_test_select)\n",
    "\n",
    "y_pred = np.argmax(y_pred_counts, axis=1)\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RH0TMNsAoMjT"
   },
   "source": [
    "3.5.3 Softmax回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-GlO3qSgtxgg",
    "outputId": "0776a013-a04f-4e88-c7e3-de0133f0d452"
   },
   "outputs": [],
   "source": [
    "mdl_softmax = LogisticRegression(max_iter=1000, solver='lbfgs')\n",
    "\n",
    "start_time = time.time()\n",
    "mdl_softmax.fit(x_train, y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f'Training time: {end_time - start_time:.2f} seconds')\n",
    "\n",
    "# Evaluate accuracy (or other metrics)\n",
    "y_pred = mdl_softmax.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LMvKrVWqpqJL",
    "outputId": "cdcb18c0-be0a-4d5d-c94a-490954f1f67d"
   },
   "outputs": [],
   "source": [
    "# One-hot encoding\n",
    "def one_hot_encode(y, num_classes):\n",
    "    \"\"\"Converts integer labels to one-hot encoding.\"\"\"\n",
    "    one_hot = np.zeros((y.shape[0], num_classes))\n",
    "    one_hot[np.arange(y.shape[0]), y] = 1\n",
    "    return one_hot\n",
    "\n",
    "# Example usage:\n",
    "num_classes = len(class_list)\n",
    "y_train_onehot = one_hot_encode(y_train, num_classes)\n",
    "\n",
    "# Display one-hot encoding results of ten random sample\n",
    "for _ in range(10):\n",
    "    idx = np.random.randint(0, y_train_onehot.shape[0])\n",
    "\n",
    "    print(f'Sample {idx+1},\\t Class {y_train[idx]}: {y_train_onehot[idx,:]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5brE3L-UsCYa"
   },
   "outputs": [],
   "source": [
    "# Softmax function\n",
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    e_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "    return e_x / e_x.sum(axis=1, keepdims=True)\n",
    "\n",
    "# Cross-entropy loss\n",
    "def cross_entropy_loss(y, y_pred):\n",
    "    \"\"\"Compute cross-entropy loss.\"\"\"\n",
    "    epsilon = 1e-15  # Small value to avoid log(0)\n",
    "    loss = -np.sum(y * np.log(y_pred + epsilon)) / y.shape[0]\n",
    "    return loss\n",
    "\n",
    "def gradient_descent(x, y, learning_rate, num_iterations):\n",
    "    \"\"\"Performs gradient descent optimization.\"\"\"\n",
    "    num_samples, num_features = x.shape\n",
    "    num_classes = y.shape[1]\n",
    "\n",
    "    # Initialize weights and bias\n",
    "    w = np.random.randn(num_features, num_classes)\n",
    "    b = np.zeros(num_classes)\n",
    "\n",
    "    for i in range(num_iterations):\n",
    "        # Forward pass\n",
    "        scores = np.dot(x, w) + b\n",
    "        y_pred = softmax(scores)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = cross_entropy_loss(y, y_pred)\n",
    "\n",
    "        # Backward pass (compute gradients), penalty 'l2'\n",
    "        dw = (1 / num_samples) * np.dot(x.T, (y_pred - y)) + 0.1 * w\n",
    "        db = (1 / num_samples) * np.sum(y_pred - y, axis=0)\n",
    "\n",
    "        # Update parameters\n",
    "        w -= learning_rate * dw\n",
    "        b -= learning_rate * db\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(f'Iteration {i}, Loss: {loss}')\n",
    "\n",
    "    return w, b\n",
    "\n",
    "def predict(x, w, b):\n",
    "    \"\"\"Predicts class labels for input data.\"\"\"\n",
    "    scores = np.dot(x, w) + b\n",
    "    y_pred = softmax(scores)\n",
    "    return np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QiU6_YBPscjL",
    "outputId": "aafc1478-c6a8-4b31-f340-d0c4264c65d4"
   },
   "outputs": [],
   "source": [
    "# Perform gradient descent\n",
    "start_time = time.time()\n",
    "w, b = gradient_descent(x_train, y_train_onehot, learning_rate=0.1, num_iterations=1000)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f'Training time: {end_time - start_time:.2f} seconds')\n",
    "\n",
    "# Make predictions\n",
    "y_pred = predict(x_test, w, b)\n",
    "\n",
    "# Evaluate accuracy (or other metrics)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "awWBO3bKYE9A"
   },
   "source": [
    "## 3.6 实验3：基于机器学习方法的手写字母识别\n",
    "\n",
    "此部分需要同学自行完成各个任务要求：\n",
    "* 数据读取、特征提取及分析\n",
    "* 分别使用逻辑回归、SVM、决策树、随机森林将手写字母分为大数（5-9）和小数（0-4）\n",
    "* 尝试结合随机森林的思想，联合多个不同的分类器进行判断\n",
    "* 使用ROC展示并分析二分类模型的结果\n",
    "* 分别以One-vs-Rest, One-vs-One和softmax的方式识别手写字母\n",
    "* 画出手写字母识别精度的分布以及混淆矩阵，并进行必要的描述与分析"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO5gS9/MePw+FDiXJA07L6y",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
